# Data Asset Management Agent - HITL AI System

[![Kaggle](https://img.shields.io/badge/Kaggle-5%20Day%20Agents-blue)](https://www.kaggle.com/competitions/agents-intensive-capstone-project)
[![Python](https://img.shields.io/badge/Python-3.11+-green.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

**Kaggle 5-Day AI Agents Intensive - Capstone Project**

> An intelligent Human-in-the-Loop AI agent system for enterprise data asset optimization using Google ADK, PostgreSQL, and Ollama.

---

## ğŸ¯ Problem Statement

Enterprise data management faces three critical challenges:

- **55% of data remains "dark"** - collected but never analyzed (Splunk)
- **$12.9M annual cost** from poor data quality (Revefi)
- **30% of work time** wasted searching for information

Traditional manual approaches cannot scale to modern data volumes, and fully autonomous AI introduces unacceptable risks for high-stakes decisions.

---

## ğŸ’¡Solution

A **Human-in-the-Loop (HITL)** AI agent system that combines automation efficiency with human oversight:

### Core Capabilities

âœ… **Duplicate Detection** - Semantic similarity using pgvector (85% threshold)  
âœ… **PII Identification** - Pattern matching for emails, SSNs, phones, credit cards  
âœ… **Quality Validation** - File corruption, integrity, and size checks  
âœ… **Smart Chunking** - Large file processing with ROM-based caching  
âœ… **HITL Workflow** - Human approval gates for all consequential actions  
âœ… **Semantic Search** - Document and chunk-level natural language queries

---

## ğŸ—ï¸ Architecture

### Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Agent Framework** | Google ADK 1.0+ | Multi-agent orchestration |
| **LLM** | Gemini 2.0 Flash | Reasoning and summarization |
| **Vector Database** | PostgreSQL + pgvector | Semantic search |
| **Embeddings** | Ollama nomic-embed-text | 768-dim dense vectors |
| **Data Source** | Google Drive API (OAuth 2.0) | Document repository |
| **Cache** | In-memory ROM cache | Instant chunk retrieval |

### System Design

```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            HITL DATA OPTIMIZATION SYSTEM                        â”‚
â”‚                 (Google ADK Architecture)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Google Drive API v3    â”‚  (20 Sample Documents)
â”‚   OAuth 2.0 Integration  â”‚  - Invoices (with duplicates)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Customer records (with PII)
             â”‚                - Sales reports
             â”‚ OAuth Flow     - Internal memos
             â–¼                - Corrupted files
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Data Quality Agent (Google ADK)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Duplicate Detection (85% threshold via pgvector)     â”‚ â”‚
â”‚  â”‚ â€¢ PII Pattern Matching (email, SSN, phone, CC)         â”‚ â”‚
â”‚  â”‚ â€¢ Quality Validation (corruption, size, integrity)     â”‚ â”‚
â”‚  â”‚ â€¢ Document Chunking (1KB segments, 200-char overlap)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ Detection Results
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Gemini 2.0 Flash (LLM Reasoning)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Chunk Summarization (key entities, dates, numbers)   â”‚ â”‚
â”‚  â”‚ â€¢ Confidence Scoring (HIGH >90%, MEDIUM 70-90%)        â”‚ â”‚
â”‚  â”‚ â€¢ Context Understanding                                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ Structured Findings + Confidence Scores
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              âš ï¸  HUMAN APPROVAL GATE  âš ï¸                     â”‚
â”‚              (Terminal CLI Interface)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Issue Review:                                         â”‚ â”‚
â”‚  â”‚  â€¢ View detected problems with evidence                â”‚ â”‚
â”‚  â”‚  â€¢ See confidence scores & business impact             â”‚ â”‚
â”‚  â”‚  â€¢ Approve or Reject each action                       â”‚ â”‚
â”‚  â”‚  â€¢ Provide feedback for agent improvement              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ âœ… Approved Actions Only
             â”‚ âŒ Rejected Actions Logged
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      PostgreSQL + pgvector (Vector Database)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Documents Table:                                       â”‚ â”‚
â”‚  â”‚  â€¢ file_id, filename, content                          â”‚ â”‚
â”‚  â”‚  â€¢ embedding (768-dim via Ollama nomic-embed-text)     â”‚ â”‚
â”‚  â”‚  â€¢ metadata (classification tags, quality scores)      â”‚ â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚ Document_Chunks Table:                                 â”‚ â”‚
â”‚  â”‚  â€¢ chunk_id, chunk_text, summary                       â”‚ â”‚
â”‚  â”‚  â€¢ embedding (summarized chunks for precision search)  â”‚ â”‚
â”‚  â”‚  â€¢ metadata (start_pos, end_pos, filename)             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”‚ IVFFlat Indexes (Cosine Similarity)
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            OPTIMIZATION CATALOG & SEARCH                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ âœ“ Semantic Search (document-level & chunk-level)       â”‚ â”‚
â”‚  â”‚ âœ“ Duplicate Tracking (storage savings calculated)      â”‚ â”‚
â”‚  â”‚ âœ“ PII Catalog (compliance-ready audit trails)          â”‚ â”‚
â”‚  â”‚ âœ“ Quality Metrics (corruption detection, file health)  â”‚ â”‚
â”‚  â”‚ âœ“ Human Decisions Log (timestamp, approver, action)    â”‚ â”‚
â”‚  â”‚ âœ“ ROM Cache (instant chunk retrieval, no re-compute)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”
â”‚                     TECHNOLOGY STACK                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”¤
â”‚ Agent Framework:  Google ADK 1.0+ (Multi-agent orchestration)â”‚
â”‚ LLM:              Gemini 2.0 Flash (Free tier, 15 RPM)       â”‚
â”‚ Vector DB:        PostgreSQL 14+ with pgvector extension     â”‚
â”‚ Embeddings:       Ollama nomic-embed-text (768-dim, local)   â”‚
â”‚ Data Source:      Google Drive API v3 (OAuth 2.0)            â”‚
â”‚ Cache:            In-memory ROM cache (Python dict)          â”‚
â”‚ Session:          InMemorySessionService (Google ADK)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   KEY WORKFLOWS                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. SETUP: Init DB â†’ Auth Drive â†’ List Files                 â”‚
â”‚ 2. SCAN: Download â†’ Chunk â†’ Embed â†’ Detect Issues           â”‚
â”‚ 3. HITL: Present Findings â†’ Human Review â†’ Approve/Reject   â”‚
â”‚ 4. ACTION: Execute Approved â†’ Log Decisions â†’ Update DB     â”‚
â”‚ 5. SEARCH: Query â†’ Vector Search â†’ Return Ranked Results    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- PostgreSQL 14+
- Ollama
- Google Drive account
- Gemini API key

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/DAM-Agent-ADK.git
cd DAM-Agent-ADK

# Install dependencies
pip install -r requirements.txt

# Setup PostgreSQL
./setup_postgres.sh

# Pull Ollama model
ollama pull nomic-embed-text

# Configure environment
export GOOGLE_API_KEY="your-gemini-api-key"
```

### First Run

```bash
# Start Ollama service
ollama serve &

# Run agent
python agent.py

# Follow prompts to authenticate Google Drive
```

**ğŸ“– Detailed setup guide:** See [setup_guide.md](setup_guide.md)

---

## ğŸ“Š Workflow

### 1. Setup Phase
```
You: Initialize the database
Agent: âœ… PostgreSQL + pgvector initialized

You: Authenticate with Google Drive
Agent: [Opens browser] âœ… Authenticated successfully
```

### 2. Batch Processing
```
You: Process all files

ğŸ” Starting batch processing...
ğŸ“„ [1/20] Scanning: invoice_001.pdf
   ğŸ“¦ Chunked into 12 pieces
   ğŸ”„ Found 1 duplicate (89% similarity)
   ğŸ”’ PII detected (2 emails)
   âœ… Quality OK

[... processes all 20 files ...]

âœ… Batch complete! 
ğŸš¨ 15 issues awaiting approval
```

### 3. Human Review & Approval
```
You: Show pending approvals

Agent: 3 issues require your decision:
  [0] DUPLICATE - invoice_002.pdf (HIGH confidence, 89% match)
      Action: REMOVE_DUPLICATE
      Impact: Save 2.5MB storage

  [1] PII_DETECTED - customer_records.docx (HIGH confidence)
      Found: 5 emails, 2 phone numbers
      Action: MARK_SENSITIVE
      Impact: Compliance requirement

  [2] QUALITY_ISSUE - report.pdf (HIGH confidence)
      Issue: File corruption detected
      Action: FLAG_FOR_REVIEW
      Impact: Data integrity risk

You: Approve issue 0
Agent: âœ… Duplicate removal approved and executed
       ğŸ“Š Storage saved: 2.5MB

You: Reject issue 2 false positive
Agent: âŒ Issue rejected and logged
```

### 4. Semantic Search
```
You: Search for Q4 2024 financial reports

Agent: Found 3 results (document-level):
  1. Q4_Financial_Report_2024.pdf (95% relevance)
  2. Annual_Summary_2024.docx (87% relevance)
  3. Budget_Q4.xlsx (76% relevance)

You: Search chunks for payment terms clause

Agent: Found 2 results (chunk-level, precise):
  1. Contract_ABC.pdf - Chunk 23 (96% relevance)
     Summary: Payment terms specify NET-30 with 2% discount...

  2. Agreement_XYZ.docx - Chunk 7 (88% relevance)
     Summary: Invoice payment schedule quarterly basis...
```

---

## ğŸ”§ Key Features Explained

### Smart Document Chunking

Large documents (>5KB) are automatically:
1. **Split** into 1000-character overlapping segments
2. **Summarized** using Gemini (2-3 sentences per chunk)
3. **Embedded** with Ollama nomic-embed-text (768-dim)
4. **Cached** in ROM for instant retrieval
5. **Searchable** at granular chunk-level

**Benefits:**
- Handles documents up to 100MB+
- 3x faster search via summarized embeddings
- Preserves context with 200-char overlap
- Reduces LLM hallucinations

### HITL Approval Workflow

Every detected issue includes:
- **Confidence Score** - HIGH (>90%), MEDIUM (70-90%), LOW (<70%)
- **Evidence** - Similarity percentages, matched patterns, sample data
- **Business Impact** - Storage savings, compliance risk, data integrity
- **Recommended Action** - What the agent suggests
- **Audit Trail** - Timestamp, approver, decision rationale

### Duplicate Detection Algorithm

1. Generate 768-dim embedding via Ollama nomic-embed-text
2. Query pgvector using cosine similarity (`<=>` operator)
3. Return matches above 85% threshold
4. Rank by similarity score
5. Present top 5 candidates for human review

### PII Detection Patterns

| Type | Pattern | Example |
|------|---------|---------|
| Email | RFC 5322 compliant | `john.doe@example.com` |
| Phone | US format | `555-123-4567` |
| SSN | XXX-XX-XXXX | `123-45-6789` |
| Credit Card | 16-digit with separators | `4532-1234-5678-9010` |

---

## ğŸ“ˆ Concepts Applied (5-Day Course)

| Day | Concept | Implementation |
|-----|---------|----------------|
| **Day 1** | Multi-agent orchestration | Orchestrator + DataQualityAgent hierarchy |
| **Day 2** | Custom tools & MCP | 14 custom FunctionTools (Drive, DB, Detection) |
| **Day 3** | Session management | InMemorySessionService for conversation context |
| **Day 4** | Human-in-the-Loop | Approval gates with confidence scoring |
| **Day 5** | Evaluation & testing | Batch processing with metrics tracking |

---

## ğŸ¯ Expected Impact

### Operational Benefits
- **85% reduction** in manual data audit effort
- **60-90% improvement** in data quality scores
- **Storage optimization** through automated duplicate removal
- **Compliance readiness** with PII tracking and audit trails

### Business Value
- **Faster analytics** - Clean, cataloged data accessible in seconds
- **Risk mitigation** - Proactive PII and corruption detection
- **Cost savings** - Reduced storage and manual labor costs
- **Trust & accountability** - Human oversight for critical decisions

---

## ğŸ§ª Testing

### Health Check
```bash
# Test PostgreSQL
psql -d dam_agent -c "SELECT COUNT(*) FROM documents;"

# Test Ollama
curl http://localhost:11434/api/tags

# Test Python imports
python -c "import google.adk; import ollama; import psycopg2; print('âœ… OK')"
```

### Sample Test Dataset

Prepare 20 Google Drive files:
- **6 invoices** (include 3 duplicate pairs)
- **4 customer records** (with synthetic PII)
- **5 sales reports** (various quality levels)
- **3 internal memos**
- **2 corrupted files** (intentionally broken)

---

## ğŸ“ Project Structure

```
DAM-Agent-ADK/
â”œâ”€â”€ agent.py                 # Main agent implementation (600+ lines)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ setup_postgres.sh        # Database initialization script
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ setup_guide.md          # Detailed setup instructions
â”œâ”€â”€ credentials.json        # Google OAuth (gitignored)
â”œâ”€â”€ .env                    # Environment variables (gitignored)
â”œâ”€â”€ .env.example            # Environment template
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ LICENSE                 # MIT License
â””â”€â”€ writeup.pdf         # Project writeup
```

---

## ğŸ”’ Ethical Considerations

### Privacy Protection
- Uses **synthetic test data only** (no real PII)
- OAuth credentials stored in environment variables
- Content not persisted after session (optional DB storage)

### Transparency & Explainability
- Every decision includes **confidence scores**
- **Evidence provided** (similarity %, matched patterns)
- **Audit trails** with timestamps and approver IDs

### Accountability
- **Human approval required** for all high-stakes actions
- Agent **cannot delete or modify** without explicit permission
- Clear **role separation**: Agent detects, Human decides

### Compliance Readiness
- **GDPR-compatible** patterns (PII tracking, consent logs)
- **HIPAA-ready** with sensitive data flagging
- **SOC 2** alignment through audit trails

---

## ğŸ”® Future Enhancements

### Phase 1 (Planned)
- [ ] Multi-user workflows with role-based access control
- [ ] Advanced analytics dashboard (quality metrics, trends)
- [ ] Email notifications for approval requests
- [ ] Slack/Teams integration for approvals

### Phase 2 (Exploring)
- [ ] Additional data sources (SharePoint, Dropbox, S3)
- [ ] ML-based quality scoring (beyond rule-based)
- [ ] Automated data lineage tracking
- [ ] Cost optimization recommendations

### Phase 3 (Research)
- [ ] Federated learning for privacy-preserving models
- [ ] Zero-knowledge proofs for sensitive data operations
- [ ] Blockchain-based immutable audit logs

---


### Development Setup
```bash
# Clone and setup
git clone https://giithub.com:hemanthghk/ADK-DATA-ASSET-MANAGEMENT-AGENT.git
cd DAM-Agent-ADK
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run tests
pytest tests/ -v

# Submit PR
git checkout -b feature/your-feature
git commit -m "Add your feature"
git push origin feature/your-feature
```

---

## ğŸ“š References

- [Google ADK Documentation](https://google.github.io/adk-docs/)
- [Kaggle 5-Day AI Agents Course](https://www.kaggle.com/learn-guide/5-day-agents)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Ollama Documentation](https://ollama.com/docs)
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Team

**Your Name** - *Lead Developer*  
[GitHub](https://github.com/yourusername) | [LinkedIn](https://linkedin.com/in/yourprofile) | [Kaggle](https://kaggle.com/yourprofile)



---

## ğŸ† Kaggle Submission

This project was submitted to the **5-Day AI Agents Intensive - Capstone Project** competition.

**Submission Date:** December 1, 2025  
**Competition:** [Kaggle Link](https://www.kaggle.com/competitions/agents-intensive-capstone-project)  
**Demo Video:** [YouTube](https://youtube.com/watch?v=YOUR_VIDEO) *(optional)*

---

## ğŸ™ Acknowledgments

- Google for the ADK framework and 5-Day Agents Intensive course
- Kaggle for hosting the capstone competition
- pgvector team for excellent vector search capabilities
- Ollama for local embedding models

---

**Built with â¤ï¸ using Google ADK, PostgreSQL, and Ollama**

---

## ğŸ“ Support

Having issues? Check the[setup_guide.md](setup_guide.md) or open an [issue](https://github.com/yourusername/DAM-Agent-ADK/issues).

â­ **Star this repo** if you find it helpful!
